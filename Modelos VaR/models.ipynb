{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4c5c0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Activos finales por región (después de todos los filtros) ---\n",
      "Geografia\n",
      "Asia ex Japón    37\n",
      "China            21\n",
      "Europe           20\n",
      "India             1\n",
      "Japan             3\n",
      "Latam            28\n",
      "USA              50\n",
      "dtype: int64\n",
      "\n",
      "--- Allocation normalizada solo en regiones presentes ---\n",
      "       Geografia      Peso  Peso_normalizado\n",
      "0            USA  0.700000          0.700000\n",
      "1         Europe  0.125000          0.125000\n",
      "2          Japan  0.071000          0.071000\n",
      "3  Asia ex Japón  0.017382          0.017382\n",
      "4          India  0.031465          0.031465\n",
      "5          China  0.030000          0.030000\n",
      "6          Latam  0.025152          0.025152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s9/mpd6xx3x1173hcqlz6vh5s_80000gn/T/ipykernel_9790/2323878229.py:64: RuntimeWarning: divide by zero encountered in matmul\n",
      "  portf_rets = S @ w\n",
      "/var/folders/s9/mpd6xx3x1173hcqlz6vh5s_80000gn/T/ipykernel_9790/2323878229.py:64: RuntimeWarning: overflow encountered in matmul\n",
      "  portf_rets = S @ w\n",
      "/var/folders/s9/mpd6xx3x1173hcqlz6vh5s_80000gn/T/ipykernel_9790/2323878229.py:64: RuntimeWarning: invalid value encountered in matmul\n",
      "  portf_rets = S @ w\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Pesos óptimos por activo (usando solo datos hasta 2023-12-31 ) ---\n",
      "                Ticker   Peso óptimo\n",
      "0       0JKT LN EQUITY  8.490032e-17\n",
      "1    AACCHIA CI EQUITY  2.115412e-02\n",
      "2       AAXJ US EQUITY  8.481641e-17\n",
      "3    ABCAI2A LX EQUITY  0.000000e+00\n",
      "4    AEEVI2E LX EQUITY  5.760004e-03\n",
      "..                 ...           ...\n",
      "156      XLU US EQUITY  1.988458e-23\n",
      "157     XUCM LN EQUITY  5.676380e-17\n",
      "158     XUFN LN EQUITY  0.000000e+00\n",
      "159     XUIN LN EQUITY  8.231693e-02\n",
      "160     XUTC LN EQUITY  5.527393e-02\n",
      "\n",
      "[161 rows x 2 columns]\n",
      "\n",
      "--- Suma de pesos por región y comparación con restricciones ---\n",
      "       Geografia  Peso óptimo  Peso_Restriccion\n",
      "0  Asia ex Japón     0.017382          0.017382\n",
      "1          China     0.030000          0.030000\n",
      "2         Europe     0.125000          0.125000\n",
      "3          India     0.031465          0.031465\n",
      "4          Japan     0.071000          0.071000\n",
      "5          Latam     0.025152          0.025152\n",
      "6            USA     0.700000          0.700000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# --- 1. Carga de datos y filtrado base ---\n",
    "prices = pd.read_excel('prices/Prices.xlsx', index_col=0)\n",
    "dict_activos = pd.read_excel('dict/dict_temp.xlsx')\n",
    "alloc = pd.read_excel('allocation/Allocation.xlsx')\n",
    "\n",
    "# Solo Equities\n",
    "equities = dict_activos[dict_activos['Asset Class'] == 'Equities']\n",
    "tickers_equities = equities['Ticker'].unique()\n",
    "tickers_validos = [t for t in tickers_equities if t in prices.columns]\n",
    "\n",
    "prices_eq = prices[tickers_validos].copy()\n",
    "min_hist = 6 * 252\n",
    "validos_hist = prices_eq.notna().sum(axis=0) >= min_hist\n",
    "prices_eq = prices_eq.loc[:, validos_hist]\n",
    "prices_eq = prices_eq.dropna(axis=0, how='any')\n",
    "\n",
    "tickers_final = list(prices_eq.columns)\n",
    "equities = equities[equities['Ticker'].isin(tickers_final)].reset_index(drop=True)\n",
    "assert list(prices_eq.columns) == list(equities['Ticker']), \"Tickers no sincronizados\"\n",
    "\n",
    "print(\"\\n--- Activos finales por región (después de todos los filtros) ---\")\n",
    "print(equities.groupby('Geografia').size())\n",
    "\n",
    "# --- NUEVO: Define fecha límite para optimización (solo usa historia hasta aquí) ---\n",
    "fecha_limite_train = '2023-12-31'\n",
    "\n",
    "prices_eq_train = prices_eq.loc[:fecha_limite_train]\n",
    "\n",
    "# --- 2. Estadísticos SOLO con training ---\n",
    "retornos_train = np.log(prices_eq_train / prices_eq_train.shift(1)).dropna()\n",
    "mu_train = retornos_train.mean().values\n",
    "Sigma_train = retornos_train.cov().values\n",
    "S_train = retornos_train.values\n",
    "n = len(tickers_final)\n",
    "\n",
    "# --- 3. Penalización por exceso de activos por región ---\n",
    "def limite_region(peso_region):\n",
    "    # Ajusta los límites a tu criterio\n",
    "    if peso_region > 0.30:\n",
    "        return 13\n",
    "    elif peso_region > 0.10:\n",
    "        return 6\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "def cardinalidad_penalizacion(w, tickers_final, equities, alloc_valid, peso_min=0.01):\n",
    "    penal = 0.0\n",
    "    for _, row in alloc_valid.iterrows():\n",
    "        geo = row['Geografia']\n",
    "        peso_geo = row['Peso_normalizado']\n",
    "        max_activos = limite_region(peso_geo)\n",
    "        tickers_region = equities[equities['Geografia'] == geo]['Ticker'].tolist()\n",
    "        idxs_region = [tickers_final.index(t) for t in tickers_region if t in tickers_final]\n",
    "        n_activos = np.sum(w[idxs_region] >= peso_min)\n",
    "        penal += max(0, n_activos - max_activos)\n",
    "    return penal\n",
    "\n",
    "# --- 4. Función objetivo: Sharpe penalizado por CVaR y cardinalidad ---\n",
    "def cvar_loss(w, S, alpha=0.05):\n",
    "    portf_rets = S @ w\n",
    "    var = np.percentile(portf_rets, 100 * alpha)\n",
    "    cvar = var + (1 / (alpha * len(portf_rets))) * np.sum(np.maximum(var - portf_rets, 0))\n",
    "    return cvar\n",
    "\n",
    "def neg_sharpe_penalized_card(w, mu, Sigma, S, alloc_valid, tickers_final, equities,\n",
    "                              lambda_cvar=0.2, lambda_card=3.0, alpha=0.05):\n",
    "    ret = np.dot(mu, w)\n",
    "    vol = np.sqrt(np.dot(w, np.dot(Sigma, w)))\n",
    "    sharpe = ret / vol if vol > 0 else -1e6\n",
    "    cvar = cvar_loss(w, S, alpha)\n",
    "    penal = cardinalidad_penalizacion(w, tickers_final, equities, alloc_valid, peso_min=0.01)\n",
    "    return - (sharpe - lambda_cvar * cvar) + lambda_card * penal\n",
    "\n",
    "# --- 5. Restricciones ---\n",
    "\n",
    "def restriccion_region(idx, p):\n",
    "    def fun(w):\n",
    "        return np.sum(w[idx]) - p\n",
    "    return fun\n",
    "\n",
    "bounds = [(0, 1)] * n\n",
    "constraints = [\n",
    "    {'type': 'eq', 'fun': lambda w: np.sum(w) - 1}\n",
    "]\n",
    "\n",
    "# --- Allocation solo en regiones válidas y normalizadas ---\n",
    "regiones_validas = []\n",
    "for _, row in alloc.iterrows():\n",
    "    geo = row['Geografia']\n",
    "    activos_geo = equities[equities['Geografia'] == geo]['Ticker']\n",
    "    if len(activos_geo) > 0:\n",
    "        regiones_validas.append(geo)\n",
    "\n",
    "alloc_valid = alloc[alloc['Geografia'].isin(regiones_validas)].copy()\n",
    "total = alloc_valid['Peso'].sum()\n",
    "alloc_valid['Peso_normalizado'] = alloc_valid['Peso'] / total\n",
    "\n",
    "print(\"\\n--- Allocation normalizada solo en regiones presentes ---\")\n",
    "print(alloc_valid[['Geografia', 'Peso', 'Peso_normalizado']])\n",
    "\n",
    "for _, row in alloc_valid.iterrows():\n",
    "    geo = row['Geografia']\n",
    "    peso_obj = row['Peso_normalizado']\n",
    "    activos_geo = equities[equities['Geografia'] == geo]['Ticker'].tolist()\n",
    "    indices = [tickers_final.index(tkr) for tkr in activos_geo if tkr in tickers_final]\n",
    "    if indices:\n",
    "        constraints.append({'type': 'eq', 'fun': restriccion_region(indices, peso_obj)})\n",
    "\n",
    "# --- 6. Optimización ---\n",
    "w0 = np.ones(n) / n\n",
    "res = minimize(\n",
    "    neg_sharpe_penalized_card, w0,\n",
    "    args=(mu_train, Sigma_train, S_train, alloc_valid, tickers_final, equities, 0.2, 3.0, 0.05),\n",
    "    bounds=bounds, constraints=constraints,\n",
    "    options={'maxiter': 1000}\n",
    ")\n",
    "\n",
    "# --- 7. Resultados ---\n",
    "pesos_opt = res.x\n",
    "resultado = pd.DataFrame({\n",
    "    'Ticker': tickers_final,\n",
    "    'Peso óptimo': pesos_opt\n",
    "})\n",
    "print(\"\\n--- Pesos óptimos por activo (usando solo datos hasta\", fecha_limite_train, \") ---\")\n",
    "print(resultado)\n",
    "\n",
    "# --- 8. Chequeo: Suma por región y comparación con Allocation.xlsx ---\n",
    "df_merge = pd.merge(resultado, equities[['Ticker', 'Geografia']], on='Ticker', how='left')\n",
    "pesos_por_region = df_merge.groupby('Geografia')['Peso óptimo'].sum().reset_index()\n",
    "\n",
    "comparacion = pd.merge(\n",
    "    pesos_por_region,\n",
    "    alloc[['Geografia', 'Peso']].rename(columns={'Peso': 'Peso_Restriccion'}),\n",
    "    on='Geografia',\n",
    "    how='outer'\n",
    ")\n",
    "\n",
    "print(\"\\n--- Suma de pesos por región y comparación con restricciones ---\")\n",
    "print(comparacion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb99b44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "914b50e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Usa el resultado y el merge con geografía que ya tienes:\n",
    "df_merge = pd.merge(resultado, equities[['Ticker', 'Geografia']], on='Ticker', how='left')\n",
    "\n",
    "# Solo activos con peso mayor a un umbral (por ejemplo, 1e-6 para limpiar los ceros \"de máquina\")\n",
    "umbral = 1e-6\n",
    "df_merge_filtrado = df_merge[df_merge['Peso óptimo'] > umbral]\n",
    "\n",
    "# Ordena por región y peso descendente\n",
    "df_merge_filtrado = df_merge_filtrado.sort_values(['Geografia', 'Peso óptimo'], ascending=[True, False])\n",
    "\n",
    "# Ahora exporta: una hoja por región, cada hoja con Ticker y Peso óptimo\n",
    "with pd.ExcelWriter('Seleccion_Activos_por_Region_activos_limitados.xlsx') as writer:\n",
    "    for region in df_merge_filtrado['Geografia'].unique():\n",
    "        df_region = df_merge_filtrado[df_merge_filtrado['Geografia'] == region][['Ticker', 'Peso óptimo']]\n",
    "        df_region.to_excel(writer, sheet_name=region, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06d33359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtra activos seleccionados y normaliza los pesos para que sumen 1 (por si acaso)\n",
    "umbral = 1e-6\n",
    "portafolio_final = resultado[resultado['Peso óptimo'] > umbral].copy()\n",
    "portafolio_final['Peso óptimo'] = portafolio_final['Peso óptimo'] / portafolio_final['Peso óptimo'].sum()\n",
    "portafolio_final = portafolio_final.sort_values('Peso óptimo', ascending=False)\n",
    "\n",
    "# Exporta a Excel\n",
    "portafolio_final.rename(columns={'Peso óptimo': 'Peso'}).to_excel('Portafolio_limitado_activos.xlsx', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
